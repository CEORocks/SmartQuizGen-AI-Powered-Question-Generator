{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration - SQuAD v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "from nltk import tokenize\n",
    "from scipy import stats\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBold(string):\n",
    "    display(Markdown('**' + string + '**'))\n",
    "    \n",
    "#def printColor():\n",
    "#     display(Markdown('<span style=\"color:blue\">blue</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we aren't really doing the answering of the questions, as is the true intention for the dataset, we'll merge the train and dev datasets into one. The test dataset is probably hidden, since there's a competition for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('../data/squad-v1/train-v1.1.json', orient='column')\n",
    "dev = pd.read_json('../data/squad-v1/dev-v1.1.json', orient='column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, dev], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'University_of_Notre_Dame', 'paragra...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Montana', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Genocide', 'paragraphs': [{'context...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Antibiotics', 'paragraphs': [{'cont...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  version\n",
       "0  {'title': 'University_of_Notre_Dame', 'paragra...      1.1\n",
       "1  {'title': 'Beyoncé', 'paragraphs': [{'context'...      1.1\n",
       "2  {'title': 'Montana', 'paragraphs': [{'context'...      1.1\n",
       "3  {'title': 'Genocide', 'paragraphs': [{'context...      1.1\n",
       "4  {'title': 'Antibiotics', 'paragraphs': [{'cont...      1.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showQuestion(titleId, paragraphId, questionId):\n",
    "\n",
    "    title = df['data'][titleId]['title']\n",
    "    paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "    question = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['question']\n",
    "    answer = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['text']\n",
    "    answerStart = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['answer_start']\n",
    "\n",
    "    printBold('Title')\n",
    "    print(title)\n",
    "    printBold('Paragraph')\n",
    "    print(paragraph)\n",
    "    printBold('Question')\n",
    "    print(question)\n",
    "    printBold('Answer')\n",
    "    print(answerStart)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "Saint Bernadette Soubirous\n"
     ]
    }
   ],
   "source": [
    "titleId = 0\n",
    "paragraphId = 0 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles 490\n",
      "Paragraphs 20963\n",
      "Questions 98169\n"
     ]
    }
   ],
   "source": [
    "titlesCount = len(df['data'])\n",
    "totalParagraphsCount = 0\n",
    "totalQuestionsCount = 0\n",
    "\n",
    "for titleId in range(titlesCount):\n",
    "    paragraphsCount = len(df['data'][titleId]['paragraphs'])\n",
    "    totalParagraphsCount += paragraphsCount\n",
    "    \n",
    "    for paragraphId in range(paragraphsCount):\n",
    "        questionsCount = len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])\n",
    "        \n",
    "        totalQuestionsCount += questionsCount\n",
    "        \n",
    "print('Titles', titlesCount)\n",
    "print('Paragraphs', totalParagraphsCount)\n",
    "print('Questions', totalQuestionsCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n",
      "Beyoncé\n",
      "Montana\n",
      "Genocide\n",
      "Antibiotics\n",
      "Frédéric_Chopin\n",
      "Sino-Tibetan_relations_during_the_Ming_dynasty\n",
      "IPod\n",
      "The_Legend_of_Zelda:_Twilight_Princess\n",
      "Spectre_(2015_film)\n",
      "2008_Sichuan_earthquake\n",
      "New_York_City\n",
      "To_Kill_a_Mockingbird\n",
      "Solar_energy\n",
      "Tajikistan\n",
      "Anthropology\n",
      "Portugal\n",
      "Kanye_West\n",
      "Buddhism\n",
      "American_Idol\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "for titleId in range(len(df['data'])):\n",
    "    titles.append(df['data'][titleId]['title'])\n",
    "    \n",
    "for i in range(20):\n",
    "    print(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles are pretty random. Seems to be a lot of locations like countries and cities but not nearly enough to afford splitting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our main assumptions is that the sentence that contains the answer could be turned into a question just by removing the answer from it. Let's see how much of that is true for the questions in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saint Bernadette Soubirous\n"
     ]
    }
   ],
   "source": [
    "titleId = 0\n",
    "paragraphId = 0 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSentence(paragraph, answerStart):\n",
    "    \n",
    "    sentences = tokenize.sent_tokenize(paragraph)\n",
    "    sentenceStart = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if (sentenceStart + len(sentence) >= answerStart):\n",
    "            return sentence         \n",
    "        \n",
    "        sentenceStart += len(sentence) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n"
     ]
    }
   ],
   "source": [
    "paragraph = df['data'][0]['paragraphs'][0]['context']\n",
    "answerStart = df['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start']\n",
    "\n",
    "sentence = extractSentence(paragraph, answerStart)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containedInText(text, question):\n",
    "    \n",
    "    questionWords = tokenize.word_tokenize(question.lower())\n",
    "    textWords = tokenize.word_tokenize(text.lower())\n",
    "    wordsContained = 0\n",
    "\n",
    "    for questionWord in questionWords:\n",
    "        for textWord in textWords:\n",
    "            if (questionWord == textWord):\n",
    "                wordsContained += 1\n",
    "                break\n",
    "\n",
    "    return wordsContained / len(questionWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "question =  df['data'][0]['paragraphs'][0]['qas'][0]['question']\n",
    "\n",
    "contained = containedInText(sentence, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Sentence**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Contained**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "printBold('Question')\n",
    "print(question)\n",
    "printBold('Sentence')\n",
    "print(sentence)\n",
    "printBold(\"Contained\")\n",
    "print(contained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wouldn't expect a 100% containment simply because the questions will contain **question-like words** like *Why, Who, *Whom*, What*.\n",
    "\n",
    "In this example we also see that the word appear is contained in the original sentence but in **past tense**. We could take care of that if we take the **stems** of the words, but I think it's better to see the least imaginative way for forming questions.\n",
    "\n",
    "We are also calculating some **common words like *to, the, in*** which could be encountered at different places of the sentence, but again we want to measure the least-creative questions.\n",
    "\n",
    "In this sentece *(damn, that was a good example)* we also see that the question uses the word *allegedly* which is a **synonym** of *reputedly* in the sentence. That could be nice for question forming, but I think it's more of an overkill.\n",
    "\n",
    "We also see that the question actually encompasses the **words around the answer, rather than the entire sentence**. Which is a definate must-do when we form our questions. \n",
    "\n",
    "Let's see what is the score on all of the questons. I'm also curious to see the score on the entire paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may come in handy in the future. Pretty printing the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printint the percentage done\n",
    "def printPercentage(currentStep, maxStep):\n",
    "    stepSize = maxStep / 100\n",
    "    \n",
    "    if (int(currentStep / stepSize) > ((currentStep - 1) / stepSize)):\n",
    "        clear_output()\n",
    "        print('{}%'.format(int(currentStep / stepSize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n"
     ]
    }
   ],
   "source": [
    "sentenceScore = []\n",
    "paragraphScore = []\n",
    "\n",
    "#For each title\n",
    "titlesCount = len(df['data'])\n",
    "for titleId in range(titlesCount):\n",
    "    printPercentage(titleId, titlesCount)\n",
    "    \n",
    "    #For each paragraph\n",
    "    for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "        paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "        \n",
    "        #For each question\n",
    "        for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "            question = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['question']\n",
    "            answerStart = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['answer_start']\n",
    "            sentence = extractSentence(paragraph, answerStart)\n",
    "          \n",
    "            sentenceScore.append(containedInText(sentence, question))\n",
    "            paragraphScore.append(containedInText(paragraph, question))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98169.000000</td>\n",
       "      <td>98169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.463937</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.190377</td>\n",
       "      <td>0.159055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence     paragraph\n",
       "count  98169.000000  98169.000000\n",
       "mean       0.463937      0.582157\n",
       "std        0.190377      0.159055\n",
       "min        0.000000      0.000000\n",
       "25%        0.333333      0.500000\n",
       "50%        0.461538      0.600000\n",
       "75%        0.600000      0.700000\n",
       "max        1.000000      1.000000"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceScoreDf = pd.DataFrame(sentenceScore, columns=['sentence'])\n",
    "paragraphScoreDf = pd.DataFrame(paragraphScore, columns=['paragraph'])\n",
    "\n",
    "questionContainmentDf = pd.concat([sentenceScoreDf, paragraphScoreDf], axis=1)\n",
    "questionContainmentDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would argue that almost half the words contained is a pretty good result. \n",
    "\n",
    "As expected, contained within the entire paragraph is better.\n",
    "\n",
    "I do wonder about those questions that are 100% contained in the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence  paragraph\n",
       "0  0.642857   0.571429\n",
       "1  0.636364   0.636364\n",
       "2  0.533333   0.600000\n",
       "3  0.375000   0.500000\n",
       "4  0.333333   0.416667\n",
       "5  0.272727   0.636364\n",
       "6  0.300000   0.800000\n",
       "7  0.363636   0.727273\n",
       "8  0.000000   0.545455\n",
       "9  0.266667   0.733333"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuestionAt(index):\n",
    "    currentIndex = 0\n",
    "    \n",
    "    for titleId in range(len(df['data'])):\n",
    "        for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "            for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "                if (currentIndex == index):\n",
    "                    return titleId, paragraphId, questionId\n",
    "                currentIndex += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see question #8 which has 0 containment in the answer sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 3)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many student news papers are found at Notre Dame?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "titleId = 0\n",
    "paragraphId = 1 \n",
    "questionId = 3\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is actually formed from the previous sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0% containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence  paragraph\n",
       "269        0.0        0.0\n",
       "363        0.0        0.0\n",
       "505        0.0        0.0\n",
       "2781       0.0        0.0\n",
       "3678       0.0        0.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf[questionContainmentDf['paragraph'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 0)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(269)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did Beyonce start becoming popular?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "in the late 1990s\n"
     ]
    }
   ],
   "source": [
    "titleId = 1\n",
    "paragraphId = 0 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **synonym** case - *instead of rose to fame*, *start becoming popular* is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18, 6)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2011, documents obtained by WikiLeaks revealed that Beyoncé was one of many entertainers who performed for the family of Libyan ruler Muammar Gaddafi. Rolling Stone reported that the music industry was urging them to return the money they earned for the concerts; a spokesperson for Beyoncé later confirmed to The Huffington Post that she donated the money to the Clinton Bush Haiti Fund. Later that year she became the first solo female artist to headline the main Pyramid stage at the 2011 Glastonbury Festival in over twenty years, and was named the highest-paid performer in the world per minute.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did this leak happen?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2011\n"
     ]
    }
   ],
   "source": [
    "titleId = 1\n",
    "paragraphId = 18 \n",
    "questionId = 6\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's just a bad question. It could only be asked in combination with the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45064</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53226</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67425</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  paragraph\n",
       "21911       1.0        1.0\n",
       "39394       1.0        1.0\n",
       "45064       1.0        1.0\n",
       "48874       1.0        1.0\n",
       "53226       1.0        1.0\n",
       "67425       1.0        1.0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf[questionContainmentDf['sentence'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 23, 0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(53226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utrecht\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utrecht city has an active cultural life, and in the Netherlands is second only to Amsterdam. There are several theatres and theatre companies. The 1941 main city theatre was built by Dudok. Besides theatres there is a large number of cinemas including three arthouse cinemas. Utrecht is host to the international Early Music Festival (Festival Oude Muziek, for music before 1800) and the Netherlands Film Festival. The city has an important classical music hall Vredenburg (1979 by Herman Hertzberger). Its acoustics are considered among the best of the 20th-century original music halls.[citation needed] The original Vredenburg music hall has been redeveloped as part of the larger station area redevelopment plan and in 2014 has gained additional halls that allowed its merger with the rock club Tivoli and the SJU jazzpodium. There are several other venues for music throughout the city. Young musicians are educated in the conservatory, a department of the Utrecht School of the Arts. There is a specialised museum of automatically playing musical instruments.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultural life in Utrecht is second to \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Utrecht city has an active cultural life, and in the Netherlands is second only to Amsterdam\n"
     ]
    }
   ],
   "source": [
    "titleId = 258\n",
    "paragraphId = 23 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strange question. The question words all appear in the sentence, but not in order. But the answer is the entire sentence, which obviously has needless information inside it. Looking further into it, the question is actually wrong, because it should state second *in Netherlands*. This question should be scrapped..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341, 25, 2)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(67425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another, is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as heat, and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomisation in a crystal).\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A reversible process is one in which this does not happen.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n",
      "dissipation\n"
     ]
    }
   ],
   "source": [
    "titleId = 341\n",
    "paragraphId = 25 \n",
    "questionId = 2\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is, basically, just the question I expect to generate. The answer is removed and the sentence is descriptive enough to fill in the missing word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assumption that the **question is mostly consisted of words from the sentence the answer is in** seems correct.\n",
    "\n",
    "There are some obvious differences like:\n",
    "- **Question-like words** are added - who, why, when...\n",
    "- **Synonyms** are used instead of the words used in the sentence\n",
    "- Changing the sentence to a question also changes the **tense** of the word.\n",
    "- In long sentences, only a **part of the sentence is used**. Like if the sentence is separated with commas, the comma actually divides two logical statements.\n",
    "\n",
    "I also managed to find some outliers which turned out to be not-so-well asked questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see:\n",
    "- Are all the answers phrases from the text\n",
    "- The type of the answers - number, dates, names, locations, close to the title\n",
    "- Part of speech - verb, noun\n",
    "- Answer lenght in words\n",
    "- Words around the answer.\n",
    "- Answer location in the sentence - First word, last word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers contained in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Answers in text**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98169\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answers not in text**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "answersInText = 0\n",
    "answersNotInText = 0\n",
    "\n",
    "for titleId in range(len(df['data'])):\n",
    "     for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "        paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "        for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "            answer = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['text']\n",
    "            if (answer in paragraph):\n",
    "                answersInText += 1\n",
    "            else:\n",
    "                answersNotInText += 1\n",
    "                \n",
    "printBold('Answers in text')\n",
    "print(answersInText)\n",
    "printBold('Answers not in text')\n",
    "print(answersNotInText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the answers are phrases from the text. Seems like that has been a requirement from the start, since the answers also have an index indicating their start location in the paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "sentences = []\n",
    "\n",
    "for titleId in range(len(df['data'])):\n",
    "    \n",
    "     for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "        paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "        \n",
    "        for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "            answer = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['text']\n",
    "            answerStart = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['answer_start']\n",
    "            \n",
    "            sentence = extractSentence(paragraph, answerStart)\n",
    "            \n",
    "            answers.append(answer)\n",
    "            sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>It is a replica of the grotto at Lourdes, Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the Main Building</td>\n",
       "      <td>Next to the Main Building is the Basilica of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    answer  \\\n",
       "0               Saint Bernadette Soubirous   \n",
       "1                a copper statue of Christ   \n",
       "2                        the Main Building   \n",
       "3  a Marian place of prayer and reflection   \n",
       "4       a golden statue of the Virgin Mary   \n",
       "\n",
       "                                            sentence  \n",
       "0  It is a replica of the grotto at Lourdes, Fran...  \n",
       "1  Immediately in front of the Main Building and ...  \n",
       "2  Next to the Main Building is the Basilica of t...  \n",
       "3  Immediately behind the basilica is the Grotto,...  \n",
       "4  Atop the Main Building's gold dome is a golden...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerTextsDf = pd.DataFrame(answers, columns=['answer'])\n",
    "sentenceDf = pd.DataFrame(sentences, columns=['sentence'])\n",
    "\n",
    "answersDf = pd.concat([answerTextsDf, sentenceDf], axis=1)\n",
    "answersDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer word lenght "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = []\n",
    "\n",
    "for i in range(len(answersDf)):\n",
    "    wordCount.append(len(tokenize.word_tokenize(answersDf.iloc[i]['answer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDf = pd.concat([answersDf, pd.DataFrame(wordCount, columns=['wordCount'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    98169.000000\n",
       "mean         3.354511\n",
       "std          3.731074\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          4.000000\n",
       "max         46.000000\n",
       "Name: wordCount, dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf['wordCount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32161"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answersDf[answersDf['wordCount'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 1/3 of the answers are single worded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "      <th>wordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>twice</td>\n",
       "      <td>The other magazine, The Juggler, is released t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>three</td>\n",
       "      <td>The nine student-run outlets include three new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1987</td>\n",
       "      <td>In 1987, when some students believed that The ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rome</td>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eight</td>\n",
       "      <td>Today the college, housed in the Fitzpatrick, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1920</td>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>five</td>\n",
       "      <td>Today the college, housed in the Fitzpatrick, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>five</td>\n",
       "      <td>All of Notre Dame's undergraduate students are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1924</td>\n",
       "      <td>This changed in 1924 with formal requirements ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1854</td>\n",
       "      <td>The university first offered graduate degrees,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1986</td>\n",
       "      <td>It was founded in 1986 through the donations o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14</td>\n",
       "      <td>The main building is the 14-story Theodore M. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer                                           sentence  wordCount\n",
       "6   twice  The other magazine, The Juggler, is released t...          1\n",
       "8   three  The nine student-run outlets include three new...          1\n",
       "9    1987  In 1987, when some students believed that The ...          1\n",
       "10   Rome  The university is the major seat of the Congre...          1\n",
       "15  eight  Today the college, housed in the Fitzpatrick, ...          1\n",
       "16   1920  The College of Engineering was established in ...          1\n",
       "18   five  Today the college, housed in the Fitzpatrick, ...          1\n",
       "21   five  All of Notre Dame's undergraduate students are...          1\n",
       "24   1924  This changed in 1924 with formal requirements ...          1\n",
       "27   1854  The university first offered graduate degrees,...          1\n",
       "31   1986  It was founded in 1986 through the donations o...          1\n",
       "34     14  The main building is the 14-story Theodore M. ...          1"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf[answersDf['wordCount'] == 1].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
